{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von waymoDataTest01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangweigang/driving/blob/master/waymoDataTest01_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYl40fniqSHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf waymo-od > /dev/null\n",
        "!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
        "!cd waymo-od && git branch -a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1835SjcCqd9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install build-essential\n",
        "!sudo apt-get install --assume-yes pkg-config zip g++ zlib1g-dev unzip python3 python3-pip\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/0.28.0/bazel-0.28.0-installer-linux-x86_64.sh\n",
        "!sudo bash ./bazel-0.28.0-installer-linux-x86_64.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_3rStKGrZpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd waymo-od && ./configure.sh && cat .bazelrc && bazel clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLntUzCmripy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd waymo-od && bazel build ... --show_progress_rate_limit=10.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Oxrc4a7DtM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd waymo-od && bazel-bin/waymo_open_dataset/metrics/tools/compute_detection_metrics_main waymo_open_dataset/metrics/tools/fake_predictions.bin  waymo_open_dataset/metrics/tools/fake_ground_truths.bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArMxYB1E9j-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd waymo-od && bazel test waymo_open_dataset/metrics/ops/... && bazel test waymo_open_dataset/metrics/python/..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytEO4tE3FHKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd waymo-od && bazel test ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HJd7SBo4_QuV",
        "colab": {}
      },
      "source": [
        "!cp /content/waymo-od/bazel-genfiles/waymo_open_dataset/label_pb2.py /content/waymo-od/waymo_open_dataset/label_pb2.py\n",
        "!cp /content/waymo-od/bazel-genfiles/waymo_open_dataset/dataset_pb2.py /content/waymo-od/waymo_open_dataset/dataset_pb2.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZwnPUOgVAHec",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import imp\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "os.environ['PYTHONPATH']='/env/python:/content/waymo-od'\n",
        "m=imp.find_module('waymo_open_dataset', ['/content/waymo-od'])\n",
        "imp.load_module('waymo_open_dataset', m[0], m[1], m[2])\n",
        "\n",
        "from waymo_open_dataset.utils import range_image_utils\n",
        "from waymo_open_dataset.utils import transform_utils\n",
        "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "29uZtYLJBx2r",
        "colab": {}
      },
      "source": [
        "FILENAME = '/content/waymo-od/tutorial/frames'\n",
        "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
        "for data in dataset:\n",
        "    frame = open_dataset.Frame()\n",
        "    frame.ParseFromString(bytearray(data.numpy()))\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHK95_JBUXUx",
        "colab": {}
      },
      "source": [
        "def parse_range_image_and_camera_projection(frame):\n",
        "  \"\"\"Parse range images and camera projections given a frame.\n",
        "\n",
        "  Args:\n",
        "     frame: open dataset frame proto\n",
        "  Returns:\n",
        "     range_images: A dict of {laser_name,\n",
        "       [range_image_first_return, range_image_second_return]}.\n",
        "     camera_projections: A dict of {laser_name,\n",
        "       [camera_projection_from_first_return,\n",
        "        camera_projection_from_second_return]}.\n",
        "    range_image_top_pose: range image pixel pose for top lidar.\n",
        "  \"\"\"\n",
        "  range_images = {}\n",
        "  camera_projections = {}\n",
        "  range_image_top_pose = None\n",
        "  for laser in frame.lasers:\n",
        "    if len(laser.ri_return1.range_image_compressed) > 0:\n",
        "      range_image_str_tensor = tf.decode_compressed(\n",
        "          laser.ri_return1.range_image_compressed, 'ZLIB')\n",
        "      ri = open_dataset.MatrixFloat()\n",
        "      ri.ParseFromString(bytearray(range_image_str_tensor.numpy()))\n",
        "      range_images[laser.name] = [ri]\n",
        "\n",
        "      if laser.name == open_dataset.LaserName.TOP:\n",
        "        range_image_top_pose_str_tensor = tf.decode_compressed(\n",
        "            laser.ri_return1.range_image_pose_compressed, 'ZLIB')\n",
        "        range_image_top_pose = open_dataset.MatrixFloat()\n",
        "        range_image_top_pose.ParseFromString(\n",
        "            bytearray(range_image_top_pose_str_tensor.numpy()))\n",
        "\n",
        "      camera_projection_str_tensor = tf.decode_compressed(\n",
        "          laser.ri_return1.camera_projection_compressed, 'ZLIB')\n",
        "      cp = open_dataset.MatrixInt32()\n",
        "      cp.ParseFromString(bytearray(camera_projection_str_tensor.numpy()))\n",
        "      camera_projections[laser.name] = [cp]\n",
        "    if len(laser.ri_return2.range_image_compressed) > 0:\n",
        "      range_image_str_tensor = tf.decode_compressed(\n",
        "          laser.ri_return2.range_image_compressed, 'ZLIB')\n",
        "      ri = open_dataset.MatrixFloat()\n",
        "      ri.ParseFromString(bytearray(range_image_str_tensor.numpy()))\n",
        "      range_images[laser.name].append(ri)\n",
        "\n",
        "      camera_projection_str_tensor = tf.decode_compressed(\n",
        "          laser.ri_return2.camera_projection_compressed, 'ZLIB')\n",
        "      cp = open_dataset.MatrixInt32()\n",
        "      cp.ParseFromString(bytearray(camera_projection_str_tensor.numpy()))\n",
        "      camera_projections[laser.name].append(cp)\n",
        "  return range_images, camera_projections, range_image_top_pose \n",
        "(range_images, camera_projections,\n",
        " range_image_top_pose) = parse_range_image_and_camera_projection(frame)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZotEevt7S0fE",
        "colab": {}
      },
      "source": [
        "print(frame.context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ne4-TpYLVCwi",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(25, 20))\n",
        "\n",
        "def image_show(data, name, layout, cmap=None):\n",
        "  \"\"\"Show an image.\"\"\"\n",
        "  plt.subplot(*layout)\n",
        "  plt.imshow(tf.image.decode_jpeg(data), cmap=cmap)\n",
        "  plt.title(name)\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "\n",
        "for index, image in enumerate(frame.images):\n",
        "  image_show(image.image, open_dataset.CameraName.Name.Name(image.name),\n",
        "             [3, 3, index+1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mwZ4xcsHVO1V",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(64, 20))\n",
        "def plot_range_image_helper(data, name, layout, vmin = 0, vmax=1, cmap='gray'):\n",
        "  \"\"\"Plots range image.\n",
        "\n",
        "  Args:\n",
        "    data: range image data\n",
        "    name: the image title\n",
        "    layout: plt layout\n",
        "    vmin: minimum value of the passed data\n",
        "    vmax: maximum value of the passed data\n",
        "    cmap: color map\n",
        "  \"\"\"\n",
        "  plt.subplot(*layout)\n",
        "  plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "  plt.title(name)\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "\n",
        "def get_range_image(laser_name, return_index):\n",
        "  \"\"\"Returns range image given a laser name and its return index.\"\"\"\n",
        "  return range_images[laser_name][return_index]\n",
        "\n",
        "def show_range_image(range_image, layout_index_start = 1):\n",
        "  \"\"\"Shows range image.\n",
        "\n",
        "  Args:\n",
        "    range_image: the range image data from a given lidar of type MatrixFloat.\n",
        "    layout_index_start: layout offset\n",
        "  \"\"\"\n",
        "  range_image_tensor = tf.convert_to_tensor(range_image.data)\n",
        "  range_image_tensor = tf.reshape(range_image_tensor, range_image.shape.dims)\n",
        "  lidar_image_mask = tf.greater_equal(range_image_tensor, 0)\n",
        "  range_image_tensor = tf.where(lidar_image_mask, range_image_tensor,\n",
        "                                tf.ones_like(range_image_tensor) * 1e10)\n",
        "  range_image_range = range_image_tensor[...,0] \n",
        "  range_image_intensity = range_image_tensor[...,1]\n",
        "  range_image_elongation = range_image_tensor[...,2]\n",
        "  plot_range_image_helper(range_image_range.numpy(), 'range',\n",
        "                   [8, 1, layout_index_start], vmax=75, cmap='gray')\n",
        "  plot_range_image_helper(range_image_intensity.numpy(), 'intensity',\n",
        "                   [8, 1, layout_index_start + 1], vmax=1.5, cmap='gray')\n",
        "  plot_range_image_helper(range_image_elongation.numpy(), 'elongation',\n",
        "                   [8, 1, layout_index_start + 2], vmax=1.5, cmap='gray')\n",
        "frame.lasers.sort(key=lambda laser: laser.name)\n",
        "show_range_image(get_range_image(open_dataset.LaserName.TOP, 0), 1)\n",
        "show_range_image(get_range_image(open_dataset.LaserName.TOP, 1), 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XIEDW1pfpmd-",
        "colab": {}
      },
      "source": [
        "def convert_range_image_to_point_cloud(frame,\n",
        "                                       range_images,\n",
        "                                       camera_projections,\n",
        "                                       range_image_top_pose,\n",
        "                                       ri_index = 0):\n",
        "  \"\"\"Convert range images to point cloud.\n",
        "\n",
        "  Args:\n",
        "    frame: open dataset frame\n",
        "     range_images: A dict of {laser_name,\n",
        "       [range_image_first_return, range_image_second_return]}.\n",
        "     camera_projections: A dict of {laser_name,\n",
        "       [camera_projection_from_first_return,\n",
        "        camera_projection_from_second_return]}.\n",
        "    range_image_top_pose: range image pixel pose for top lidar.\n",
        "    ri_index: 0 for the first return, 1 for the second return.\n",
        "  Returns:\n",
        "    points: {[N, 3]} list of 3d lidar points of length 5 (number of lidars).\n",
        "    cp_points: {[N, 6]} list of camera projections of length 5\n",
        "      (number of lidars).\n",
        "  \"\"\"\n",
        "  calibrations = sorted(frame.context.laser_calibrations, key=lambda c: c.name)\n",
        "  lasers = sorted(frame.lasers, key=lambda laser: laser.name)\n",
        "  points = [] \n",
        "  cp_points = []\n",
        "  \n",
        "  frame_pose = tf.convert_to_tensor(\n",
        "      np.reshape(np.array(frame.pose.transform), [4, 4]))\n",
        "  # [H, W, 6]\n",
        "  range_image_top_pose_tensor = tf.reshape(\n",
        "      tf.convert_to_tensor(range_image_top_pose.data),\n",
        "      range_image_top_pose.shape.dims)\n",
        "  # [H, W, 3, 3]\n",
        "  range_image_top_pose_tensor_rotation = transform_utils.get_rotation_matrix(\n",
        "      range_image_top_pose_tensor[..., 0], range_image_top_pose_tensor[..., 1],\n",
        "      range_image_top_pose_tensor[..., 2])\n",
        "  range_image_top_pose_tensor_translation = range_image_top_pose_tensor[..., 3:]\n",
        "  range_image_top_pose_tensor = transform_utils.get_transform(\n",
        "      range_image_top_pose_tensor_rotation,\n",
        "      range_image_top_pose_tensor_translation)\n",
        "  for c in calibrations:\n",
        "    range_image = range_images[c.name][ri_index]\n",
        "    if len(c.beam_inclinations) == 0:\n",
        "      beam_inclinations = range_image_utils.compute_inclination(\n",
        "          tf.constant([c.beam_inclination_min, c.beam_inclination_max]),\n",
        "          height=range_image.shape.dims[0])\n",
        "    else:\n",
        "      beam_inclinations = tf.constant(c.beam_inclinations)\n",
        "\n",
        "    beam_inclinations = tf.reverse(beam_inclinations, axis=[-1])\n",
        "    extrinsic = np.reshape(np.array(c.extrinsic.transform), [4, 4])\n",
        "\n",
        "    range_image_tensor = tf.reshape(\n",
        "        tf.convert_to_tensor(range_image.data), range_image.shape.dims)\n",
        "    pixel_pose_local = None\n",
        "    frame_pose_local = None\n",
        "    if c.name == open_dataset.LaserName.TOP:\n",
        "      pixel_pose_local = range_image_top_pose_tensor\n",
        "      pixel_pose_local = tf.expand_dims(pixel_pose_local, axis=0)\n",
        "      frame_pose_local = tf.expand_dims(frame_pose, axis=0)\n",
        "    range_image_mask = range_image_tensor[..., 0] > 0\n",
        "    range_image_cartesian = range_image_utils.extract_point_cloud_from_range_image(\n",
        "        tf.expand_dims(range_image_tensor[..., 0], axis=0),\n",
        "        tf.expand_dims(extrinsic, axis=0),\n",
        "        tf.expand_dims(tf.convert_to_tensor(beam_inclinations), axis=0),\n",
        "        pixel_pose=pixel_pose_local,\n",
        "        frame_pose=frame_pose_local)\n",
        "\n",
        "    range_image_cartesian = tf.squeeze(range_image_cartesian, axis=0)\n",
        "    points_tensor = tf.gather_nd(range_image_cartesian,\n",
        "                                 tf.where(range_image_mask))\n",
        "\n",
        "    cp = camera_projections[c.name][0]\n",
        "    cp_tensor = tf.reshape(tf.convert_to_tensor(cp.data), cp.shape.dims)\n",
        "    cp_points_tensor = tf.gather_nd(cp_tensor, tf.where(range_image_mask))\n",
        "    points.append(points_tensor.numpy())\n",
        "    cp_points.append(cp_points_tensor.numpy())\n",
        "\n",
        "  return points, cp_points\n",
        "\n",
        "points, cp_points = convert_range_image_to_point_cloud(frame,\n",
        "                                                       range_images,\n",
        "                                                       camera_projections,\n",
        "                                                       range_image_top_pose)\n",
        "points_ri2, cp_points_ri2 = convert_range_image_to_point_cloud(\n",
        "    frame,\n",
        "    range_images,\n",
        "    camera_projections,\n",
        "    range_image_top_pose,\n",
        "    ri_index=1)\n",
        "\n",
        "# 3d points in vehicle frame.\n",
        "points_all = np.concatenate(points, axis=0)\n",
        "points_all_ri2 = np.concatenate(points_ri2, axis=0)\n",
        "# camera projection corresponding to each point.\n",
        "cp_points_all = np.concatenate(cp_points, axis=0)\n",
        "cp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bpsAJp2CqKrE",
        "colab": {}
      },
      "source": [
        "print(points_all.shape)\n",
        "print(cp_points_all.shape)\n",
        "print(points_all[0:2])\n",
        "for i in range(5):\n",
        "  print(points[i].shape)\n",
        "  print(cp_points[i].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K8VFnGnOq6cO",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image('/content/waymo-od/tutorial/3d_point_cloud.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yRMUN-hur9wO",
        "colab": {}
      },
      "source": [
        "images = sorted(frame.images, key=lambda i:i.name)\n",
        "cp_points_all_concat = np.concatenate([cp_points_all, points_all], axis=-1)\n",
        "cp_points_all_concat_tensor = tf.constant(cp_points_all_concat)\n",
        "\n",
        "# The distance between lidar points and vehicle frame origin.\n",
        "points_all_tensor = tf.norm(points_all, axis=-1, keepdims=True)\n",
        "cp_points_all_tensor = tf.constant(cp_points_all, dtype=tf.int32)\n",
        "\n",
        "mask = tf.equal(cp_points_all_tensor[..., 0], images[0].name)\n",
        "\n",
        "cp_points_all_tensor = tf.cast(tf.gather_nd(\n",
        "    cp_points_all_tensor, tf.where(mask)), dtype=tf.float32)\n",
        "points_all_tensor = tf.gather_nd(points_all_tensor, tf.where(mask))\n",
        "\n",
        "projected_points_all_from_raw_data = tf.concat(\n",
        "    [cp_points_all_tensor[..., 1:3], points_all_tensor], axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Invsxz0xsXNA",
        "colab": {}
      },
      "source": [
        "def rgba(r):\n",
        "  \"\"\"Generates a color based on range.\n",
        "\n",
        "  Args:\n",
        "    r: the range value of a given point.\n",
        "  Returns:\n",
        "    The color for a given range\n",
        "  \"\"\"\n",
        "  c = plt.get_cmap('jet')((r % 20.0) / 20.0)\n",
        "  c = list(c)\n",
        "  c[-1] = 0.5  # alpha\n",
        "  return c\n",
        "\n",
        "def plot_image(camera_image):\n",
        "  \"\"\"Plot a cmaera image.\"\"\"\n",
        "  plt.figure(figsize=(20, 12))\n",
        "  plt.imshow(tf.image.decode_jpeg(camera_image.image))\n",
        "  plt.grid(\"off\")\n",
        "\n",
        "def plot_points_on_image(projected_points, camera_image, rgba_func,\n",
        "                         point_size=5.0):\n",
        "  \"\"\"Plots points on a camera image.\n",
        "\n",
        "  Args:\n",
        "    projected_points: [N, 3] numpy array. The inner dims are\n",
        "      [camera_x, camera_y, range].\n",
        "    camera_image: jpeg encoded camera image.\n",
        "    rgba_func: a function that generates a color from a range value.\n",
        "    point_size: the point size.\n",
        "\n",
        "  \"\"\"\n",
        "  plot_image(camera_image)\n",
        "\n",
        "  xs = []\n",
        "  ys = []\n",
        "  colors = []\n",
        "\n",
        "  for point in projected_points:\n",
        "    xs.append(point[0])  # width, col\n",
        "    ys.append(point[1])  # height, row\n",
        "    colors.append(rgba_func(point[2]))\n",
        "\n",
        "  plt.scatter(xs, ys, c=colors, s=point_size, edgecolors=\"none\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fx7mUQM2saI-",
        "colab": {}
      },
      "source": [
        "plot_points_on_image(projected_points_all_from_raw_data,\n",
        "                     images[0], rgba, point_size=5.0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}